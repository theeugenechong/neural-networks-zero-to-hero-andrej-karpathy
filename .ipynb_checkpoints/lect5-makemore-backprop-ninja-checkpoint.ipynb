{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ceb0c1",
   "metadata": {},
   "source": [
    "### makemore: becoming a backprop ninja\n",
    "\n",
    "swole doge style, and NOT `loss.backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c529da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ad889fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81bd660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'} {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0} 27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos, stoi, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38070a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "    X, Y = [], []\n",
    "  \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fada1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e92b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647a904",
   "metadata": {},
   "source": [
    "Note: we are initialising many of these parameters in non-standard ways because sometimes initializating with e.g. all zeros could mask an incorrect implementation of the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22597a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22310bc",
   "metadata": {},
   "source": [
    "The forward pass here is significantly expanded from what we are used to. We implement cross entropy loss by hand.\n",
    "\n",
    "We also have a lot more intermediate tensors along the way, as we are about to go backwards and compute the gradient from *the bottom to the top*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e38e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0105, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76222c78",
   "metadata": {},
   "source": [
    "As a primer for `dlogprobs`, `dlogprobs` means the derivative of the loss w.r.t. all elements in it. So, since `logprobs` has shape (32, 27), `dlogprobs` will also have the same shape.\n",
    "\n",
    "How is `loss` related to `logprobs`?\n",
    "\n",
    "`loss = -logprobs[range(n), Yb].mean()`\n",
    "\n",
    "`Yb` holds the index of the next character predicted.\n",
    "This is plucking out the log probability of the character predicted for each row.\n",
    "\n",
    "Only the elements which are plucked out affect the loss (their loss is $\\frac{1}{n}$), the rest have gradients $0$.\n",
    "\n",
    "**Pro-tip:** Scrutinise the shapes of tensors you are dealing with first before trying to backprop. Try out with some toy examples, i.e. small matrices, then generalise.\n",
    "\n",
    "*Sum-Broadcasting Duality*: When there is a `.sum()` in the forward pass, the backward pass will tend to have some replication/broadcasting, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6a2509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "\n",
    "# dloss/dprobs = dloss/dlogprobs * dlogprobs/dprobs\n",
    "dprobs = dlogprobs * (1.0 / probs)\n",
    "\n",
    "# take note of broadcasting happening here (accounts for the .sum()), dcounts_sum_inv is a column tensor\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "\n",
    "# note that counts is used twice above, so we need to add terms together\n",
    "dcounts = (counts_sum_inv * dprobs) \n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "\n",
    "# addition of second term of dcounts\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum # let broadcasting do the work\n",
    "\n",
    "# counts = norm_logits.exp(), to avoid recomputing we reuse counts here\n",
    "dnorm_logits = counts * dcounts\n",
    "\n",
    "# note that logits is used twice, so similar to above we need to add a second term. There is implicit broadcasting for subtraction of\n",
    "# logit_maxes from logits\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "\n",
    "# second term of dlogits\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "\n",
    "# derivations of the matrox multiplication derivatives are below\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "\n",
    "# applied a tanh, derivative of tanh is 1 - tanh^2\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "\n",
    "# batch norm bias scaling and shifting\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "\n",
    "# dbndiff will have 2 terms as it is being used in another place, we're not done here\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "\n",
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "\n",
    "# broadcasting\n",
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "\n",
    "# second term of dbndiff\n",
    "dbndiff += 2 * bndiff * dbndiff2\n",
    "\n",
    "# there is broadcasting in forward pass, so there'll be sum here\n",
    "# there is a second term of dhprebn used by bnmeani\n",
    "dhprebn = 1 * dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "\n",
    "# the next term\n",
    "dhprebn += (1.0/n) * torch.ones_like(hprebn) * dbnmeani\n",
    "\n",
    "# linear layer, matmul derivative\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0, keepdim=True)\n",
    "\n",
    "# this part is just changing the view, so you undo the change\n",
    "demb = dembcat.view(emb.shape)\n",
    "\n",
    "# pluck out the relevant rows of C (our lookup) and find out each rows gradient (how each row affects loss) \n",
    "# we use += because the same row (char) is present in different parts of the input Xb\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k, j]\n",
    "        dC[ix] += demb[k, j]\n",
    "\n",
    "# check our gradients' correctness with PyTorch's\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b7829",
   "metadata": {},
   "source": [
    "**Matrix multiplication derivative** derivations can be seen here\n",
    "\n",
    "![matmul derivative](./img/matmul_derivative.jpg)\n",
    "\n",
    "The **batch normalisation equations** are as follows:\n",
    "![batchnorm](./img/bn_equations.jpg)\n",
    "\n",
    "**More on Bessel's correction** here:\n",
    "\n",
    "https://math.oxford.emory.edu/site/math117/besselCorrection/\n",
    "\n",
    "https://www.uio.no/studier/emner/matnat/math/MAT4010/data/forelesningsnotater/bessel-s-correction---wikipedia.pdf\n",
    "\n",
    "Essentially, it uses $n-1$ instead of $n$ as the denominator in the computation of variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba20a5",
   "metadata": {},
   "source": [
    "### Treating cross entropy as one whole operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab33ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0105338096618652 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab31c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.51925802230835e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass (a significantly shorter version once you know the mathematical expression)\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "\n",
    "# subtract a 1 at the correct locations\n",
    "dlogits[range(n), Yb] -= 1\n",
    "\n",
    "# take the mean\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f09c98",
   "metadata": {},
   "source": [
    "**Cross entropy loss derivative** derivation\n",
    "\n",
    "![ce-loss](./img/ce_loss_backprop.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3aad10",
   "metadata": {},
   "source": [
    "Note that the values aren't exactly equal due to floating point errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc96e6",
   "metadata": {},
   "source": [
    "Let's make some observations about `logits` and `dlogits`. \n",
    "\n",
    "What is `logits` intuitively? It is the probability matrix in the forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45064be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0226, 0.0136, 0.0394, 0.0129, 0.0427, 0.0153, 0.0715, 0.0369, 0.0525,\n",
       "        0.0570, 0.0225, 0.0395, 0.0320, 0.0268, 0.0178, 0.0407, 0.0729, 0.0376,\n",
       "        0.0391, 0.0188, 0.0448, 0.0344, 0.1170, 0.0100, 0.0248, 0.0293, 0.0276],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02e4392b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0226,  0.0136,  0.0394,  0.0129,  0.0427,  0.0153,  0.0715,  0.0369,\n",
       "        -0.9475,  0.0570,  0.0225,  0.0395,  0.0320,  0.0268,  0.0178,  0.0407,\n",
       "         0.0729,  0.0376,  0.0391,  0.0188,  0.0448,  0.0344,  0.1170,  0.0100,\n",
       "         0.0248,  0.0293,  0.0276], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n # scale it back up by n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5cda9",
   "metadata": {},
   "source": [
    "Observe that the values in the cell above are all exactly equal to the `softmax` cell, except for the position of the correct/predicted index (-0.9475) where we subtracted 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "576bf9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3970e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum() # sums to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d347cc6",
   "metadata": {},
   "source": [
    "We should think of each gradients as a *force*. We pull down of the probabilities of the incorrect characters, and pull up on the correct predicted character.\n",
    "\n",
    "The amount of *upward pull* by the predicted character is equivalent to the *downward pull* of the rest of the characters (because they sum to 0).\n",
    "\n",
    "Then think of the neural net as a pulley system, where as we *pull up* the probability of the correct character, since everything is mathematically related, this *pull* is transmitted throughout the entire net, all the way to the weights and biases.\n",
    "\n",
    "The amount in which you predict correctly (the probability) is proportional to how much you *pull up* its value in the next round.\n",
    "\n",
    "If there is a very confidently mispredicted character, it will be *pulled down* very heavily compared to the others.\n",
    "\n",
    "The worse of a mistake you make, the worse the consequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6af6f312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x244892037d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511a564",
   "metadata": {},
   "source": [
    "### Treating batch normalisation as one whole operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d74f6d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf60c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7412\n",
      "  10000/ 200000: 2.1548\n",
      "  20000/ 200000: 2.4134\n",
      "  30000/ 200000: 2.4613\n",
      "  40000/ 200000: 2.0034\n",
      "  50000/ 200000: 2.2989\n",
      "  60000/ 200000: 2.4809\n",
      "  70000/ 200000: 2.0219\n",
      "  80000/ 200000: 2.3156\n",
      "  90000/ 200000: 2.0980\n",
      " 100000/ 200000: 1.9932\n",
      " 110000/ 200000: 2.3459\n",
      " 120000/ 200000: 1.9753\n",
      " 130000/ 200000: 2.4399\n",
      " 140000/ 200000: 2.3035\n",
      " 150000/ 200000: 2.1712\n",
      " 160000/ 200000: 1.9982\n",
      " 170000/ 200000: 1.8305\n",
      " 180000/ 200000: 1.9674\n",
      " 190000/ 200000: 1.9197\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5855a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#     cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44065ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d256465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.070674180984497\n",
      "val 2.1097352504730225\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "    }[split]\n",
    "    emb = C[x] # (N, block_size, n_embd)\n",
    "    embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "    h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "    logits = h @ W2 + b2 # (N, vocab_size)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I achieved:\n",
    "# train 2.0718822479248047\n",
    "# val 2.1162495613098145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d34baf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "mayah.\n",
      "see.\n",
      "mad.\n",
      "ryla.\n",
      "reisha.\n",
      "endraegan.\n",
      "chedielin.\n",
      "shi.\n",
      "jen.\n",
      "eden.\n",
      "sana.\n",
      "arleigh.\n",
      "malaia.\n",
      "noshubergihirael.\n",
      "kindreelynn.\n",
      "novana.\n",
      "ubeka.\n",
      "dariyah.\n",
      "faeha.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "        # forward pass\n",
    "        emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "        embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "        logits = h @ W2 + b2 # (N, vocab_size)\n",
    "        # sample\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
